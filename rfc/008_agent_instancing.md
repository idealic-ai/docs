# 008: Agent/Instancing

> **Instancing:** The process of handling multiple, independent `Instances` (each with its own `State Object` and unique identifier) within a single agent request.
>
> — [Glossary](./000_glossary.md)

> Sidenote:
>
> - Requires: [Agent: State](./007_agent_state.md)
> - Compatible:
>   - [Agent: Input](./005_agent_input.md)
>   - [Agent: Imports](./006_agent_imports.md)
>   - [Agent: Plan](./009_agent_plan.md)

This document outlines a protocol for processing multiple, independent instances within a single agent request, using a state-driven architecture.

## 1. Foundational Requirement: The State System

The core prerequisite for this instancing protocol is the **State System**, which explicitly decouples the planning of actions from their execution.

The **State Object** is the bridge between these phases. It is a mutable, JSON-like object that serves two critical functions:

1.  **Target for Execution**: It is the canvas upon which tools operate. Every `Tool Call` includes an `_outputPath` property, which specifies a path within the `State` object where the tool's output should be written during execution.
2.  **Source for Dependencies**: A `Tool Call` can reference a value from the `State` as one of its inputs. This allows for the creation of dependency graphs.

## 2. The Instancing Mechanism

The true power of this architecture is revealed in its native support for multi-instance operations, which is enabled by the State System.

### 2.1. State Identifiers

To process multiple instances in a single request, the system accepts an array of context messages. Each message representing a distinct instance is assigned a **unique identifier** via a special `_instance` property. These identifiers are short, unique tokens (e.g., circled numbers like `①`, `②`) that are easily visible to the LLM but carry no semantic meaning beyond their function as a reference.

### 2.2. Targeted Operations

This `_instance` is then used to target all operations to a specific instance's context. Furthermore, all meta-parameters for a `Tool Call` are prefixed with an underscore (`_`), and its `params` are inlined directly into the call object.

- **`Tool Call` Association**: Each `Tool Call` in the generated plan contains the `_instance` of the context it should operate on.
- **Implicit Scoping**: The `_instance` on a `Tool Call` implicitly scopes all path-based operations (`_outputPath` and input references) within that call. This means that when a tool reads from or writes to a state object, the path is relative to the `_instance` of the context it belongs to.

This mechanism allows the definitions of the tools themselves to remain simple and agnostic of the instancing context. The `_outputPath` and input references within a tool's schema do not need to be updated; the identifier cleanly separates the operational contexts.

### 2.3. Example

A single request might contain two state objects for sentiment analysis. The schema for the state can be provided to constrain the available properties and guide the LLM.

```json
{
  "context": [
    {
      "_instance": "①",
      "type": "state",
      "state": { "text": "This is wonderful!" },
      "schema": {
        "type": "object",
        "properties": {
          "text": { "type": "string" },
          "sentiment": { "type": "string" }
        },
        "required": ["text"]
      }
    },
    { "_instance": "②", "type": "state", "state": { "text": "This is terrible." } }
  ]
}
```

The LLM processes both in a single context and generates a unified plan:

```json
{
  "calls": [
    {
      "_tool": "analyzeSentiment",
      "_instance": "①",
      "text": "†state.text",
      "_outputPath": "sentiment"
    },
    {
      "_tool": "analyzeSentiment",
      "_instance": "②",
      "text": "†state.text",
      "_outputPath": "sentiment"
    }
  ]
}
```

The host environment then executes this plan, writing the results to the respective state objects.

## 3. Complementary System: The Planning Graph

While not a strict requirement for instancing, the **Planning System** works symbiotically with this architecture to enable highly predictable, reusable workflows.

A **Plan** is a template for a process, defined as a directed acyclic graph (DAG) of `Tool Calls`. This graph is generated by analyzing the dependencies between tools reading from and writing to a `State Object`.

Crucially, this plan can be generated and perfected _before_ execution. Once finalized, the plan can be passed as a `Context Message` to the agent. When processing multiple instances, the agent can then follow this pre-defined plan for each `State Object`, achieving highly consistent and predictable results across multiple invocations. The `State Object` for each instance serves as a snapshot of its current position within that execution graph.

## 4. Advantages of this Approach

This state-driven instancing model provides significant benefits:

- **Efficiency**: It multiplies the throughput of the system by processing many instances in a single LLM request, dramatically improving speed and reducing costs.
- **Consistency & Quality**: By allowing the LLM to see multiple related instances in a single context, it can generate more consistent and higher-quality plans, leveraging patterns across all instances.
- **Predictability**: When combined with a pre-defined **Plan**, the system can achieve deterministic outcomes. The deterministic execution loop ensures that once a plan is followed, its outcome is reliable and repeatable across every instance.
