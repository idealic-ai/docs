# 001: Агент/Запрос

> **Запрос:** единичный, самодостаточный вызов LLM, который принимает `context` и `schema` и выдает `solution`. — [Глоссарий](./000_glossary.md)

> Sidenote: 
> ```mermaid
> graph TD
>     subgraph Ввод пользователя
>         direction LR
>         Context[\Контекст\]
>         Schema[\Схема\]
>     end
> 
>     Process{{"Запрос"}}
> 
>     subgraph Вывод LLM
>         direction LR
>         Solution[/Решение/]
>     end
> 
>     Context --> Process
>     Schema --> Process
>     Process --> Solution
>     Schema -.-> Solution
> 
>     linkStyle 2 stroke-width:2px,fill:none,stroke:gray,stroke-dasharray: 5 5;
>     linkStyle 3 stroke-width:2px,fill:none,stroke:gray,stroke-dasharray: 5 5;
> ```

`Запрос` — это основной вычислительный элемент системы агентов. Он предоставляет структурированный, воспроизводимый и расширяемый способ взаимодействия с LLM, превращая насыщенный контекст и декларативную схему в точное, структурированное решение. В отличие от простого промпта, `Запрос` — это полная, самодостаточная единица работы, служащая движком для всех высокоуровневых возможностей агента.

## Контекст: Конвейер Сообщений

> Sidenote: LLM обработает `context`, чтобы сгенерировать `solution`, которое соответствует `schema`.

Основой `Запроса` является его `context`: массив объектов `Message`. Каждое `Message` — это простая структура, содержащая `role` (например, `"system"`, `"user"` или `"assistant"`) и `content`. Эта структура позволяет передать LLM насыщенный, многоэтапный диалог.

В отличие от обычной чат-модели, где сообщения постоянно добавляются в растущую историю, `context` для каждого `Запроса` — это полностью управляемый, автономный пакет. Он тщательно формируется для конкретной задачи и не загрязняется предыдущими, не связанными с ней взаимодействиями. Ответы LLM не добавляются обратно автоматически; контекст перестраивается для каждого нового вычисления. Это обеспечивает воспроизводимость процесса и гарантирует, что LLM получит именно ту информацию, которая ей нужна, без риска обрезки контекста или «забывания» важных деталей.

Этот управляемый контекст является основным механизмом для передачи LLM промптов, данных и инструкций. Всё, что требуется для вычисления, за исключением конечной `schema` вывода, доставляется через эти сообщения.

Простой массив `Message` может выглядеть так:

```json
[
  { "role": "system", "content": "You are a helpful assistant." },
  { "role": "user", "content": "What is the capital of France?" }
]
```

Система расширяет эту базовую структуру `Message`, позволяя полю `content` содержать не только текст, но и специальные объекты, называемые **пользовательскими типами контента**. Например, вместо строки, содержимое сообщения может быть структурированным объектом, таким как `{ "type": "input", "input": { ... } }`.

> Sidenote: Пользовательские типы сообщений, описанные в Актах:
> 
> - [006: Агент/Данные](./006_agent_data.md) - представляет данные и их значение для LLM в виде сообщения
> - [007: Агент/Ввод](./007_agent_input.md) - структурированный промпт для использования LLM
> - [010: Агент/Состояние](./010_agent_state.md) - постоянное состояние, сохраняемое в цикле
> - [012: Агент/План](./012_agent_plan.md) - подготовленный план для многошагового выполнения

Эта возможность делает `context` основной точкой расширения в системе.

Каждый пользовательский тип контента регистрируется с обработчиком, и эти обработчики формируют конвейер обработки. Прежде чем `Запрос` будет отправлен в LLM, конвейер обрабатывает каждое сообщение в `context`. Обработчик сообщения может динамически изменять основные компоненты `Запроса`:

- **Конфигурация LLM**: Настройка параметров, таких как модель, температура или другие настройки.
- **Схема**: Изменение JSON-схемы, которой должен соответствовать конечный вывод.
- **Контекст**: Изменение окончательного списка сообщений, которые будут отправлены в LLM, например, путем преобразования пользовательского типа в текстовое представление или добавления новых сообщений.

Этот мощный механизм конвейера позволяет агенту работать с высокоуровневыми, структурированными концепциями, динамически конструируя точный вызов LLM, необходимый для выполнения задачи.

## Схема: Направляя Решение

> Sidenote: Узнайте больше на [json-schema.org](https://json-schema.org/)

`Схема` — это JSON Schema, которая определяет точную структуру желаемого `solution`. Это мощная система, позволяющая представлять любые типы данных, от простых строк до сложных, вложенных объектов. LLM вынуждена генерировать `solution`, которое строго соответствует этой схеме, гарантируя, что вывод всегда будет хорошо структурированным и предсказуемым.

По мере усложнения схем они могут быть спроектированы так, чтобы направлять не только конечный вывод, но и процесс рассуждений LLM. Например, схема может включать поля для самих данных, а также отдельные поля, которые побуждают LLM изложить свои рассуждения, цепочку мыслей или оценку уверенности. Это превращает схему в активный инструмент для формирования процесса генерации.

Основной принцип этой архитектуры — композиция схем. Более сложные возможности строятся путем объединения более простых, повторно используемых компонентов схем, что обеспечивает модульный и масштабируемый подход к определению знаний и способностей агента.

## Исполнение и Решение

После обработки `context`, окончательный массив сообщений и `schema` отправляются в LLM одним запросом. Ответ LLM — это `solution` — структурированный JSON-документ, который строго соответствует предоставленной `schema`.

Этот процесс можно понимать как генерацию мини-повествования. Поскольку LLM работает как предсказатель следующего токена, она генерирует `solution` сверху вниз, следуя структуре `schema`. Порядок и дизайн полей схемы напрямую влияют на повествование, которое создает LLM.

Например, если схема сначала требует поле для мета-рассуждений (например, `"thought_process"`), а затем поле для конечных `data`, LLM вынуждена сначала сформулировать свои рассуждения, а затем выдать ответ. Начальное рассуждение становится частью контекста, который влияет на генерацию последующих данных. Этот мощный механизм позволяет нам направлять мышление LLM, давая нам значительный контроль над конечным результатом, формируя сам путь, по которому она к нему приходит.

> [!TIP]
> Вся эта цепочка `Запроса` — `context`, `schema` и итоговое `solution` — образует самодостаточную, воспроизводимую единицу. При сохранении эта единица становится тем, что система называет [101: Концепция/Идея](./101_concept_idea.md).

## От Структурированного Вывода к Действенным Выборам

`Запрос` предоставляет надежный механизм для генерации единого, соответствующего схеме `solution`. Однако для создания сложных агентов нам нужно больше, чем просто структурированный вывод. Нам нужен способ представить LLM меню возможностей — отдельных действий, из которых она может выбирать для достижения цели. Это требует системы для определения этих действий как дискретных, выбираемых единиц.

> Sidenote: [002: Агент/Инструмент](./002_agent_tool.md)

Следующий документ, [002: Агент/Инструмент](./002_agent_tool.md), представляет протокол для определения этих возможностей.