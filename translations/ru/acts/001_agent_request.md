# 001: Агент/Запрос

> [!DEFINITION] [Запрос](./000_glossary.md)
> Единичный, самодостаточный вызов LLM, который принимает `context` и `schema` и выдает `solution`.

> Sidenote: Обеспечивает: [101: Концепция/Идея](./101_concept_idea.md)
> 
> NPM: [https://www.npmjs.com/package/@augceo/agent](@idealic-ai/agent)

`Request` — это основной вычислительный примитив системы агентов. Он предоставляет структурированный, воспроизводимый и расширяемый конвейер для взаимодействия с LLM, превращая насыщенный `context` и декларативную `schema` в точное, структурированное `solution`. В отличие от простого промпта, `Request` — это полная, самодостаточная единица работы, которая служит двигателем для всех высокоуровневых возможностей агента.

## Контекст: Конвейер Сообщений

> Sidenote: LLM обработает `context` для генерации `solution`, которое соответствует `schema`.
> 
> ```mermaid
> graph TD
>     subgraph Ввод пользователя
>         direction LR
>         Контекст[\Контекст\]
>         Схема[\Схема\]
>     end
> 
>     Process{{"Запрос"}}
> 
>     subgraph Вывод LLM
>         direction LR
>         Решение[/Решение/]
>     end
> 
>     Контекст --> Process
>     Схема --> Process
>     Process --> Решение
>     Схема -.-> Решение
> 
>     linkStyle 2 stroke-width:2px,fill:none,stroke:gray,stroke-dasharray: 5 5;
>     linkStyle 3 stroke-width:2px,fill:none,stroke:gray,stroke-dasharray: 5 5;
> ```

Основой `Request` является его `context`: массив объектов `Message`. Каждый `Message` — это простая структура, содержащая `role` (например, `"system"`, `"user"` или `"assistant"`) и `content`. Эта структура позволяет представить LLM насыщенный, многоходовый диалог.

В отличие от типичной чат-модели, где сообщения постоянно добавляются к растущей истории, `context` для каждого `Request` — это полностью управляемый, автономный пакет. Он тщательно создается для конкретной задачи и не загрязняется предыдущими, не связанными с ней взаимодействиями. Ответы LLM не добавляются обратно автоматически; `context` перестраивается для каждого нового вычисления. Это обеспечивает воспроизводимость процесса и точное предоставление LLM необходимой информации без риска усечения контекста или "забывания" важных деталей.

Этот управляемый `context` является основным механизмом для предоставления LLM промптов, данных и инструкций. Все, что требуется для вычисления, за исключением конечной `schema` вывода, передается через эти сообщения.

Простой массив `Message` может выглядеть так:

```json
[
  { "role": "system", "content": "Ты — полезный ассистент." },
  { "role": "user", "content": "Какая столица Франции?" }
]
```

Система расширяет эту базовую структуру `Message`, позволяя полю `content` содержать не только текст, но и специализированные объекты, называемые **пользовательскими типами содержимого**. Например, вместо строки содержимое сообщения может быть структурированным объектом, таким как `{ "type": "input", "input": { ... } }`.

> Sidenote: Пользовательские типы сообщений, описанные в Актах:
> 
> - [006: Агент/Данные](./006_agent_data.md) - представление данных и их значения LLM в виде сообщения
> - [007: Агент/Ввод](./007_agent_input.md) - структурированный промпт для использования LLM
> - [009: Агент/Состояние](./009_agent_state.md) - постоянное состояние, сохраняемое в цикле
> - [010: Агент/План](./010_agent_plan.md) - подготовленный план для многошагового выполнения

Эта возможность делает `context` основной точкой расширения в системе.

Каждый пользовательский тип содержимого регистрируется с обработчиком, и эти обработчики формируют конвейер обработки. Перед отправкой `Request` в LLM, конвейер обрабатывает каждое сообщение в `context`. Обработчик сообщения может динамически изменять основные компоненты `Request`:

- **Конфигурация LLM**: Настройка таких параметров, как модель, температура или другие опции.
- **Schema**: Изменение JSON-схемы, которой должен соответствовать конечный вывод.
- **Context**: Изменение итогового списка сообщений, который будет отправлен в LLM, например, путем преобразования пользовательского типа в текстовое представление или добавления новых сообщений.

Этот мощный механизм конвейера позволяет агенту работать с высокоуровневыми, структурированными концепциями, динамически конструируя точный вызов LLM, необходимый для выполнения задачи.

## Схема: Направляя Решение

> Sidenote: Узнать больше на [json-schema.org](https://json-schema.org/)

`schema` — это JSON Schema, которая определяет точную структуру желаемого `solution`. Это мощная система, которая позволяет представлять любые типы данных, от простых строк до сложных, вложенных объектов. LLM вынужден генерировать `solution`, которое строго соответствует этой `schema`, гарантируя, что вывод всегда будет хорошо структурирован и предсказуем.

По мере усложнения схем их можно проектировать так, чтобы они направляли не только конечный вывод, но и процесс рассуждений LLM. Например, `schema` может включать поля для самих данных, а также отдельные поля, которые побуждают LLM изложить свои рассуждения, цепочку мыслей или оценку уверенности. Это превращает `schema` в активный инструмент для формирования процесса генерации.

Основным принципом этой архитектуры является композиция схем. Более сложные возможности строятся путем объединения более простых, повторно используемых компонентов схем, что обеспечивает модульный и масштабируемый подход к определению знаний и способностей агента.

## Исполнение и Решение

После обработки `context`, итоговый массив сообщений и `schema` отправляются в LLM одним запросом. Ответ LLM — это `solution` — структурированный, JSON-документ, который строго соответствует предоставленной `schema`.

Этот процесс можно понимать как генерацию мини-повествования. Поскольку LLM работает как предсказатель следующего токена, он генерирует `solution` сверху вниз, следуя структуре `schema`. Порядок и дизайн полей `schema` напрямую влияют на повествование, которое создает LLM.

Например, если `schema` сначала требует поле для мета-рассуждений (например, `"thought_process"`), а затем поле для конечных `data`, LLM вынужден сначала сформулировать свои рассуждения, прежде чем выдать ответ. Начальное рассуждение становится частью `context`, который влияет на генерацию последующих данных. Этот мощный механизм позволяет нам направлять мышление LLM, предоставляя значительный контроль над конечным результатом путем формирования самого пути, по которому он к нему приходит.

> [!HEADSUP] Внимание
> Весь этот конвейер `Request` — `context`, `schema` и итоговый `solution` — образует самодостаточную, воспроизводимую единицу. При сохранении эта единица в системе называется [101: Концепция/Идея](./101_concept_idea.md).

## От Структурированного Вывода к Действенным Выборам

`Request` предоставляет надежный механизм для генерации одного `solution`, соответствующего `schema`. Однако для создания сложных агентов нам нужно нечто большее, чем просто структурированный вывод. Нам нужен способ предоставить LLM меню возможностей — отдельных действий, из которых он может выбирать для достижения цели. Это требует системы для определения этих действий как дискретных, выбираемых единиц.

> Sidenote: [002: Агент/Инструмент](./002_agent_tool.md)

Следующий документ, [002: Агент/Инструмент](./002_agent_tool.md), представляет протокол для определения этих возможностей.