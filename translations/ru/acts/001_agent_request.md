# 001: Агент/Запрос

> [!DEFINITION] [Запрос](./000_glossary.md)
> Единый, самодостаточный вызов LLM, который принимает :term[контекст]{canonical="context"} и :term[схему]{canonical="schema"} и создает :term[решение]{canonical="Solution"}.

> Sidenote:
> - Включает:
>   - :term[101: Концепция/Идея]{href="./101_concept_idea.md"}
> - Ссылки:
>   - [NPM: @idealic/agent](https://www.npmjs.com/package/@augceo/agent)

:term[Запрос]{canonical="Request"} — это ключевой вычислительный примитив агентной системы. Он предоставляет структурированный, воспроизводимый и расширяемый конвейер для взаимодействия с LLM, превращая обширный контекст и декларативную схему в точное структурированное решение. В отличие от простого промпта, :term[Запрос]{canonical="Request"} — это завершенная, самодостаточная единица работы, которая служит движком для всех высокоуровневых возможностей агента.

## Контекст: Конвейер Сообщений

> [!DEFINITION] Контекст
> Специально составленный массив объектов `Message`, который предоставляет полный набор информации — инструкции, данные и историю переписки — необходимой LLM для выполнения конкретной задачи.

> Sidenote:
> LLM обработает :term[контекст]{canonical="context"} для создания :term[решения]{canonical="Solution"}, соответствующего :term[схеме]{canonical="schema"}.
>
> ```mermaid
> graph TD
>     subgraph Ввод пользователя
>         direction LR
>         Context[\Контекст\]
>         Schema[\Схема\]
>     end
>
>     Process{{"Запрос"}}
>
>     subgraph Вывод LLM
>         direction LR
>         Solution[/Решение/]
>     end
>
>     Context --> Process
>     Schema --> Process
>     Process --> Solution
>     Schema -.-> Solution
>
>     linkStyle 2 stroke-width:2px,fill:none,stroke:gray,stroke-dasharray: 5 5;
>     linkStyle 3 stroke-width:2px,fill:none,stroke:gray,stroke-dasharray: 5 5;
> ```

Основой :term[Запроса]{canonical="Request"} является его :term[контекст]{canonical="context"}: массив объектов `Message`. Каждый `Message` — это простая структура, содержащая `role` (например, `"system"`, `"user"` или `"assistant"`) и `content`. Эта структура позволяет представить LLM насыщенный, многоэтапный разговор.

В отличие от типичной модели чата, где сообщения постоянно добавляются в растущую историю, :term[контекст]{canonical="context"} для каждого :term[Запроса]{canonical="Request"} — это полностью управляемый, автономный пакет. Он тщательно создается для конкретной задачи и не «загрязняется» предыдущими, не связанными взаимодействиями. Ответы LLM не добавляются обратно автоматически; контекст пересобирается для каждого нового вычисления. Это гарантирует воспроизводимость процесса и то, что LLM получает именно ту информацию, которая ей нужна, без риска усечения контекста или «забывания» важных деталей.

Этот управляемый контекст является основным механизмом для предоставления LLM промптов, данных и инструкций. Всё, что требуется для вычисления, за исключением итоговой :term[схемы]{canonical="schema"}, доставляется через эти сообщения.

Простой массив `Message` может выглядеть так:

```json
[
  { "role": "system", "content": "Ты — полезный ассистент." },
  { "role": "user", "content": "Какая столица Франции?" }
]
```

Система расширяет эту базовую структуру `Message`, позволяя полю `content` содержать не только текст, но и специализированные объекты, называемые **пользовательскими типами контента**. Например, вместо строки, содержимое сообщения может быть структурированным объектом, таким как `{ "type": "input", "input": { ... } }`.

> Sidenote:
> Пользовательские типы сообщений, описанные в Актах:
>
> - :term[005: Агент/Данные]{href="./005_agent_data.md"} - представляет данные и их значение для LLM в виде сообщения
> - :term[006: Агент/Ввод]{href="./006_agent_input.md"} - структурированный промпт для использования LLM
> - :term[009: Агент/Состояние]{href="./009_agent_state.md"} - постоянное состояние, сохраняемое в цикле
> - :term[011: Агент/План]{href="./011_agent_plan.md"} - подготовленный план для многошагового выполнения
> - :term[015: Агент/Мета]{href="./015_agent_meta.md"} - предоставляет идентификатор Идеи для LLM

Эта возможность делает :term[контекст]{canonical="context"} основной точкой расширения в системе.

Каждый пользовательский тип контента регистрируется с обработчиком, и эти обработчики формируют конвейер обработки. Прежде чем :term[Запрос]{canonical="Request"} будет отправлен LLM, конвейер обрабатывает каждое сообщение в :term[контексте]{canonical="context"}. Обработчик сообщения может динамически изменять ключевые компоненты :term[Запроса]{canonical="Request"}:

- **Конфигурация LLM**: Настройка параметров, таких как модель, температура или другие настройки.
- **:term[Схема]{canonical="schema"}**: Изменение JSON-схемы, которой должен соответствовать итоговый вывод.
- **:term[Контекст]{canonical="context"}**: Изменение итогового списка сообщений, который будет отправлен LLM, например, преобразуя пользовательский тип в текстовое представление или добавляя новые сообщения.

Этот мощный механизм конвейера позволяет агенту работать с высокоуровневыми, структурированными концепциями, динамически создавая точный вызов LLM, необходимый для выполнения задачи.

## Схема: Направляя Решение

> [!DEFINITION] Схема
> JSON-схема, которая определяет точную структуру желаемого :term[решения]{canonical="Solution"}. Она действует как шаблон для заполнения, которому LLM должна следовать, гарантируя, что вывод всегда будет хорошо структурирован и предсказуем.

> Sidenote:
> - Читать далее на [json-schema.org](https://json-schema.org/)

:term[Схема]{canonical="schema"} — это JSON-схема, которая определяет точную структуру желаемого :term[решения]{canonical="Solution"}. Это мощная система, позволяющая представлять любые типы данных, от простых строк до сложных вложенных объектов. LLM вынуждена генерировать :term[решение]{canonical="Solution"}, которое строго соответствует этой схеме, что гарантирует, что вывод всегда будет хорошо структурирован и предсказуем.

По мере усложнения схем, их можно проектировать так, чтобы они направляли не только итоговый вывод, но и мыслительный процесс LLM. Например, :term[схема]{canonical="schema"} может включать поля для самих данных, а также отдельные поля, которые побуждают LLM изложить свои рассуждения, цепочку мыслей или оценки уверенности. Это превращает схему в активный инструмент для формирования процесса генерации.

Основным принципом этой архитектуры является композиция схем. Более сложные возможности создаются путем объединения более простых, повторно используемых компонентов схем, что обеспечивает модульный и масштабируемый подход к определению знаний и способностей агента.

## Выполнение и Решение

> [!DEFINITION] Решение
> Структурированный документ в формате JSON, возвращаемый LLM, который строго соответствует предоставленной :term[схеме]{canonical="schema"}. Это окончательный, корректно сформированный результат :term[Запроса]{canonical="Request"}.

После обработки :term[контекста]{canonical="context"}, итоговый массив сообщений и :term[схема]{canonical="schema"} отправляются LLM в одном запросе. Ответ LLM — это :term[решение]{canonical="Solution"} — структурированный документ в формате JSON, который строго соответствует предоставленной :term[схеме]{canonical="schema"}.

Этот процесс можно рассматривать как генерацию мини-повествования. Поскольку LLM работает как предсказатель следующего токена, она генерирует :term[решение]{canonical="Solution"} сверху вниз, следуя структуре :term[схемы]{canonical="schema"}. Порядок и дизайн полей схемы напрямую влияют на повествование, которое создает LLM.

Например, если схема сначала требует поле для мета-рассуждений (например, `"thought_process"`) перед полем для итоговых :term[данных]{canonical="Data"}, LLM вынуждена сначала сформулировать свои рассуждения, прежде чем выдать ответ. Первоначальное рассуждение становится частью контекста, который влияет на генерацию последующих данных. Этот мощный механизм позволяет нам направлять мышление LLM, давая нам значительный контроль над конечным результатом, формируя сам путь, по которому она к нему приходит.

> [!HEADSUP] На заметку
> Весь этот конвейер :term[Запроса]{canonical="Request"} — :term[контекст]{canonical="context"}, :term[схема]{canonical="schema"} и итоговое :term[решение]{canonical="Solution"} — образует самодостаточную, воспроизводимую единицу. При сохранении эта единица — то, что система называет :term[101: Концепция/Идея]{href="./101_concept_idea.md"}.

## От Структурированного Вывода к Действенным Выборам

:term[Запрос]{canonical="Request"} предоставляет надежный механизм для генерации одного :term[решения]{canonical="Solution"}, соответствующего схеме. Однако, чтобы создавать сложных агентов, нам нужно нечто большее, чем просто структурированный вывод. Нам нужен способ предоставить LLM меню возможностей — отдельных действий, из которых она может выбирать для достижения цели. Для этого требуется система для определения этих действий как дискретных, выбираемых единиц.

> Sidenote:
> - :term[002: Агент/Инструмент]{href="./002_agent_tool.md"}

Следующий документ, :term[002: Агент/Инструмент]{href="./002_agent_tool.md"}, представляет протокол для определения этих возможностей.
