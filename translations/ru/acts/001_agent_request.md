# 001: Агент/Запрос

> **Request:** Запрос — это единичный, самодостаточный вызов LLM, который принимает `context` и `schema` и производит `solution`. — [Глоссарий](./000_glossary.md)

> Sidenote: Основа для: [101: Концепция/Идея](./101_concept_idea.md)
>
> NPM: [https://www.npmjs.com/package/@augceo/agent](@idealic-ai/agent)

`Request` — это основной вычислительный примитив системы агентов. Он предоставляет структурированный, воспроизводимый и расширяемый конвейер для взаимодействия с LLM, превращая насыщенный контекст и декларативную схему в точное, структурированное решение. В отличие от простого промпта, `Request` — это полная, самодостаточная единица работы, которая служит двигателем для всех более высокоуровневых возможностей агента.

## Контекст: Конвейер Сообщений

> Sidenote: LLM обработает `context`, чтобы сгенерировать `solution`, соответствующий `schema`.
>
> ```mermaid
> graph TD
>     subgraph Ввод пользователя
>         direction LR
>         Context[\Контекст\]
>         Schema[\Схема\]
>     end
>
>     Process{{"Запрос"}}
>
>     subgraph Вывод LLM
>         direction LR
>         Solution[/Решение/]
>     end
>
>     Context --> Process
>     Schema --> Process
>     Process --> Solution
>     Schema -.-> Solution
>
>     linkStyle 2 stroke-width:2px,fill:none,stroke:gray,stroke-dasharray: 5 5;
>     linkStyle 3 stroke-width:2px,fill:none,stroke:gray,stroke-dasharray: 5 5;
> ```

Основой `Request` является его `context`: массив объектов `Message`. Каждый `Message` — это простая структура, содержащая `role` (например, `"system"`, `"user"` или `"assistant"`) и `content`. Такая структура позволяет представить LLM насыщенный, многоэтапный диалог.

В отличие от типичной чат-модели, где сообщения постоянно добавляются в растущую историю, `context` для каждого `Request` — это полностью управляемый, автономный пакет. Он тщательно создаётся для конкретной задачи и не загрязняется предыдущими, не связанными с ней взаимодействиями. Ответы LLM не добавляются обратно автоматически; контекст перестраивается для каждого нового вычисления. Это гарантирует воспроизводимость процесса и то, что LLM получает именно ту информацию, которая ей нужна, без риска усечения контекста или "забывания" важных деталей.

Этот управляемый контекст является основным механизмом для предоставления LLM промптов, данных и инструкций. Всё, что требуется для вычисления, за исключением итоговой `schema` вывода, передаётся через эти сообщения.

Простой массив `Message` может выглядеть так:

```json
[
  { "role": "system", "content": "Вы — полезный помощник." },
  { "role": "user", "content": "Какая столица Франции?" }
]
```

#### Конвейер контента

Система расширяет эту базовую структуру `Message`, позволяя полю `content` содержать не только текст, но и специальные объекты, называемые **пользовательскими типами контента**. Например, вместо строки контентом сообщения может быть структурированный объект, такой как `{ "type": "input", "input": { ... } }`.

> Sidenote: Пользовательские типы сообщений, описанные в Актах:
>
> - [006: Агент/Данные](./006_agent_data.md) — представление данных и их значения для LLM в виде сообщения
> - [007: Агент/Ввод](./007_agent_input.md) — структурированный промпт для использования LLM
> - [010: Агент/Состояние](./010_agent_state.md) — постоянное состояние, сохраняемое в цикле
> - [012: Агент/План](./012_agent_plan.md) — подготовленный план для многошагового выполнения

Эта возможность делает `context` основной точкой расширения в системе.

Каждый пользовательский тип контента регистрируется с обработчиком, и эти обработчики формируют конвейер обработки. Перед отправкой `Request` в LLM конвейер обрабатывает каждое сообщение в `context`. Обработчик сообщения может динамически изменять основные компоненты `Request`:

- **Конфигурация LLM**: Настройка таких параметров, как модель, температура или другие опции.
- **Схема**: Изменение JSON-схемы, которой должен соответствовать конечный вывод.
- **Контекст**: Изменение итогового списка сообщений, который будет отправлен в LLM, например, путём преобразования пользовательского типа в текстовое представление или добавления новых сообщений.

Этот мощный механизм конвейера позволяет агенту работать с высокоуровневыми, структурированными концепциями, динамически создавая именно тот вызов LLM, который необходим для выполнения задачи.

## Схема: Направляя решение

`schema` — это JSON Schema, которая определяет точную структуру желаемого `solution`. Это мощная система, позволяющая представлять любые типы данных, от простых строк до сложных вложенных объектов. LLM вынуждена генерировать `solution`, который строго соответствует этой схеме, что гарантирует постоянную структурированность и предсказуемость вывода.

По мере усложнения схем их можно проектировать так, чтобы они направляли не только конечный вывод, но и процесс рассуждения LLM. Например, схема может включать поля для самих данных, а также отдельные поля, которые побуждают LLM изложить свои рассуждения, цепочку мыслей или оценку уверенности. Это превращает схему в активный инструмент для формирования процесса генерации.

Основной принцип этой архитектуры — композиция схем. Более сложные возможности создаются путём объединения более простых, повторно используемых компонентов схем, что обеспечивает модульный и масштабируемый подход к определению знаний и способностей агента.

## Выполнение и решение

После обработки `context` итоговый массив сообщений и `schema` отправляются в LLM в одном запросе. Ответ LLM — это `solution` — структурированный JSON-документ, который строго соответствует предоставленной `schema`.

Этот процесс можно рассматривать как создание мини-повествования. Поскольку LLM работает как предсказатель следующего токена, она генерирует `solution` сверху вниз, следуя структуре `schema`. Порядок и дизайн полей схемы напрямую влияют на повествование, которое создаёт LLM.

Например, если схема сначала требует поле для мета-рассуждений (например, `"thought_process"`), а затем поле для итоговых `data`, LLM вынуждена сначала сформулировать свои рассуждения, а уже потом выдать ответ. Первоначальное рассуждение становится частью контекста, который влияет на генерацию последующих данных. Этот мощный механизм позволяет нам направлять мышление LLM, давая значительный контроль над конечным результатом, формируя сам путь к нему.

> [!TIP]
> Весь этот конвейер `Request` — `context`, `schema` и итоговый `solution` — образует самодостаточную, воспроизводимую единицу. В сохранённом виде эта единица и есть то, что система называет [101: Концепция/Идея](./101_concept_idea.md).

## От структурированного вывода к выбору действий

`Request` предоставляет надёжный механизм для генерации одного `solution`, соответствующего схеме. Однако для создания сложных агентов нам нужно нечто большее, чем просто структурированный вывод. Нам нужен способ предложить LLM меню возможностей — отдельных действий, из которых она может выбирать для достижения цели. Это требует системы для определения этих действий как дискретных, выбираемых единиц.

> Sidenote: [002: Агент/Инструмент](./002_agent_tool.md)

Следующий документ, [002: Агент/Инструмент](./002_agent_tool.md), представляет протокол для определения этих возможностей.
