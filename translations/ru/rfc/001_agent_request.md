# 101: Agent: Request

> Sidenote: NPM: [https://www.npmjs.com/package/@augceo/agent](@idealic-ai/agent)

> **Request:** Единичный, самодостаточный вызов LLM, который принимает `context` (контекст) и `schema` (схему) для получения `solution` (решения).
>
> — [Глоссарий](./000_glossary.md)

Этот документ описывает **Request Protocol** (протокол запроса), который определяет фундаментальную единицу взаимодействия с LLM. `Request` — это механизм, который делает абстрактную концепцию **[Concept: Idea](./001_concept_idea.md)** (Идея) вычислимой, принимая её `context` и `schema` для генерации `solution`.

## Конвейер обработки Request

`Request` — это не просто промпт. Это структурированный конвейер, который преобразует богатый, многосоставный контекст в единый, соответствующий схеме ответ от LLM.

### 1. Context: Массив сообщений

Основой `Request` является его `context`, который предоставляется в виде массива объектов `Message` (сообщений). Это позволяет структурированно представить LLM сложный, многоэтапный или многоролевой диалог.

Простой `context` может выглядеть так:

```json
[
  { "role": "system", "content": "You are a helpful assistant." },
  { "role": "user", "content": "What is the capital of France?" }
]
```

### 2. Пользовательские типы контента

Система расширяет эту базовую структуру, допуская **пользовательские типы контента** в сообщениях. Вместо обычной строки, `content` (содержимое) сообщения может быть структурированным объектом, например `{ "type": "state", "state": { ... } }`.

Эти пользовательские типы определяются и управляются системой `Content` (см. `agent/src/Content/Content.ts`). Каждый пользовательский тип регистрируется с обработчиком, и эти обработчики формируют конвейер обработки. При обработке каждого сообщения его обработчик может изменять три основных компонента `Request`:

- **Конфигурация LLM**: Настройка параметров, таких как модель, температура или другие опции.
- **Schema**: Изменение JSON-схемы, которой должен соответствовать конечный результат.
- **Context**: Изменение итогового списка сообщений, который будет отправлен в LLM, например, путём преобразования пользовательского типа в текстовое представление или добавления новых сообщений.

Этот мощный механизм конвейера позволяет агенту работать с высокоуровневыми, структурированными концепциями, динамически создавая именно тот вызов LLM, который необходим для выполнения задачи.

### 3. Schema: Направляя решение

`schema` — это JSON Schema, которая определяет точную структуру желаемого `solution`. Функция `Request` анализирует возможности целевого провайдера LLM, чтобы определить лучший способ принудительного применения схемы:

1.  **Нативный режим JSON Schema**: Если провайдер его поддерживает (как новые модели OpenAI), схема передается напрямую в поле `response_format` API-вызова. Это самый надежный метод.
2.  **Резервный вариант с вызовом инструментов (Tool-Calling)**: Если провайдер поддерживает вызов инструментов, но не нативный режим схемы, система оборачивает схему в инструмент-функцию с именем `generate_response` и указывает модели вызвать этот инструмент.
3.  **Режим JSON с внедрением в промпт**: В крайнем случае, для провайдеров, которые поддерживают только общий вывод в формате JSON, система указывает модели сгенерировать JSON-объект и внедряет схему в виде строки в системный промпт.

### 4. Выполнение и `solution` (решение)

После предварительной обработки итоговый массив сообщений и стратегия применения схемы упаковываются в единый API-запрос и отправляются в LLM. Затем LLM генерирует ответ, соответствующий схеме.

Система разбирает (парсит) этот ответ — будь то содержимое сообщения или аргументы вызова инструмента — в структурированный JavaScript-объект. Этот объект и есть `solution`.

Весь этот конвейер — от обработки сложного контекста до получения проверенного по схеме решения — позволяет концепции **Idea** (Идея) функционировать в качестве основного вычислительного примитива в системе.