# 101: Агент: Запрос

> **Запрос:** единичный, самодостаточный вызов LLM, который принимает `контекст` и `схему` и создает `решение`.
>
> — [Глоссарий](./000_glossary.md)

> Sidenote: NPM: [https://www.npmjs.com/package/@augceo/agent](@idealic-ai/agent)

Этот документ описывает **протокол Запроса**, который определяет фундаментальную единицу взаимодействия с LLM. `Запрос` — это движок, который делает абстрактное **[Скрытое: Идея](./001_concept_idea.md)** вычислимым, принимая его `контекст` и `схему` для генерации `решения`.

## Пайплайн Запроса

`Запрос` — это не просто промпт. Это структурированный пайплайн, который преобразует богатый, многосоставный контекст в единый, соответствующий схеме ответ от LLM.

### 1. Контекст: Массив Сообщений

Основой `Запроса` является его `контекст`, который предоставляется в виде массива объектов `Message`. Это позволяет представлять LLM сложный, многоэтапный или многоролевой диалог в структурированном виде.

Простой контекст может выглядеть так:

```json
[
  { "role": "system", "content": "You are a helpful assistant." },
  { "role": "user", "content": "What is the capital of France?" }
]
```

### 2. Пользовательские Типы Контента

Система расширяет эту базовую структуру, допуская **пользовательские типы контента** в сообщениях. Вместо обычной строки `content` сообщения может быть структурированным объектом, например, `{ "type": "state", "state": { ... } }`.

Эти пользовательские типы определяются и управляются системой `Контента` (см. `agent/src/Content/Content.ts`). Каждый пользовательский тип регистрируется с обработчиком, и эти обработчики формируют пайплайн обработки. По мере обработки каждого сообщения его обработчик может изменять три основных компонента `Запроса`:

- **Конфигурация LLM**: Настройка параметров, таких как модель, температура или другие опции.
- **Схема**: Изменение JSON-схемы, которой должен соответствовать конечный результат.
- **Контекст**: Изменение итогового списка сообщений, который будет отправлен в LLM, например, путем преобразования пользовательского типа в текстовое представление или добавления новых сообщений.

Этот мощный механизм пайплайна позволяет агенту работать с высокоуровневыми, структурированными концепциями, динамически формируя точный вызов LLM, необходимый для выполнения задачи.

### 3. Схема: Направляя Решение

`схема` — это JSON Schema, которая определяет точную структуру желаемого `решения`. Функция `Запроса` анализирует возможности целевого LLM-провайдера, чтобы определить наилучший способ принудительного применения схемы:

1.  **Нативный режим JSON Schema**: Если провайдер его поддерживает (как новые модели OpenAI), схема передается напрямую в поле `response_format` в API-вызове. Это самый надежный метод.
2.  **Запасной вариант через вызов инструментов (Tool-Calling)**: Если провайдер поддерживает вызов инструментов, но не нативный режим схемы, система оборачивает схему в инструмент-функцию с именем `generate_response` и дает модели инструкцию вызвать этот инструмент.
3.  **Режим JSON с инъекцией в промпт**: В крайнем случае, для провайдеров, которые поддерживают только общий вывод JSON, система дает модели инструкцию сгенерировать JSON-объект и вставляет схему в виде строки в системный промпт.

### 4. Исполнение и Решение

После предварительной обработки финальный массив сообщений и стратегия применения схемы упаковываются в единый API-запрос и отправляются в LLM. Затем LLM генерирует ответ, соответствующий схеме.

Система парсит этот ответ — будь то из содержимого сообщения или из аргументов вызова инструмента — в структурированный JavaScript-объект. Этот объект и является `решением`.

Весь этот пайплайн — от обработки сложного контекста до получения проверенного по схеме решения — и позволяет **Идее** функционировать как основной вычислительный примитив в системе.